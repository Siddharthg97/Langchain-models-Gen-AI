{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhqN6k_C8UDD"
      },
      "outputs": [],
      "source": [
        "# !pip install langgraph\n",
        "# !pip install transformers\n",
        "# from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "# !pip install pulp\n",
        "# from langchain.tools import tool\n",
        "# from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "# from langgraph.prebuilt import create_react_agent\n",
        "# from langgraph.graph import StateGraph, END\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gACJlKJkbv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvU_NdWUOgYh",
        "outputId": "8af273e1-abf6-4e09-f519-dd6c504630c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.68)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.4)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.9)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.68)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.5.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.72)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.68)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.5.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.72)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.7)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.68)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.3.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain_experiment (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain_experiment\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install langgraph langchain openai networkx pulp\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain_experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i6rDFnhB5Si"
      },
      "outputs": [],
      "source": [
        "# from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import pulp\n",
        "# from langchain_experimental.chat_models import HuggingFaceChat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuv1SFNh8rrP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVPx5Nww8y5O"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC2NUh3prpAk"
      },
      "source": [
        "### Code -1 (Langgraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3HrquhYVjD6"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuA-HUOdprxj"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.prebuilt import create_react_agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLcbD2CGeyL7"
      },
      "outputs": [],
      "source": [
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAM50WbvdaMH",
        "outputId": "ee0e7712-21ce-4639-c35a-e5c5fdf8cbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'status': 'Optimal', 'objective': 920.0, 'assignment': {'unloading': 3.0, 'scanning': 2.0, 'putaway': 4.0}}\n"
          ]
        }
      ],
      "source": [
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"b2c pickup\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"b2c pickup\": 110\n",
        "    }\n",
        "}\n",
        "class AgentState(TypedDict):\n",
        "    requirements: dict\n",
        "    costs: dict\n",
        "    result: dict\n",
        "\n",
        "tools = [optimize_labor]\n",
        "# agent_node = create_react_agent(model=model, tools=tools)\n",
        "# Create LangGraph\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHzYn83s-_UV"
      },
      "source": [
        "## Code -2 langchain based react agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ====== OBJECTIVE FUNCTIONS ======\n",
        "\n",
        "# 1. Total Labor Cost (to minimize)\n",
        "total_cost = pulp.lpSum(\n",
        "    # Cost of regular hours for permanent employees\n",
        "    regular_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of overtime hours for permanent employees\n",
        "    overtime_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift] *\n",
        "    overtime_premium\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    hourly_cost[('External', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# 2. Productivity (to maximize, so we negate it for minimization problem)\n",
        "total_productivity = pulp.lpSum(\n",
        "    # Productivity from permanent employees\n",
        "    (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "    productivity_rate[('Permanent', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Productivity from external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    productivity_rate[('External', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# # 3. Overtime cost (to minimize)\n",
        "# overtime_cost = pulp.lpSum(\n",
        "#     overtime_hours_permanent[(skillset, shift)] *\n",
        "#     hourly_cost[('Permanent', skillset)] *\n",
        "#     shift_premium[shift] *\n",
        "#     overtime_premium\n",
        "#     for skillset in skillsets\n",
        "#     for shift in shifts\n",
        "# )\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Normalize the objectives for proper weighting\n",
        "# We'll use estimated maximum values based on the problem context\n",
        "max_cost_estimate = 50000  # Estimated max possible cost\n",
        "max_productivity_estimate = 30000  # Estimated max possible productivity\n",
        "# max_overtime_cost_estimate = 15000  # Estimated max overtime cost\n",
        "\n",
        "normalized_cost = total_cost / max_cost_estimate\n",
        "normalized_productivity = total_productivity / max_productivity_estimate\n",
        "# normalized_overtime = overtime_cost / max_overtime_cost_estimate\n",
        "\n",
        "# Combined multi-objective function with weights\n",
        "model += (\n",
        "    weight_cost * normalized_cost -\n",
        "    weight_productivity * normalized_productivity\n",
        "    # weight_overtime * normalized_overtime\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "D1gPYv1R3Jxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9fe7ad69-e3d8-4c5d-e891-438e0b0c9007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pulp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-547069992.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. Total Labor Cost (to minimize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m total_cost = pulp.lpSum(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Cost of regular hours for permanent employees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mregular_hours_permanent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskillset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pulp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMp-9jK6yDyK",
        "outputId": "a84dfbd9-615c-4aba-b019-43efd546a4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Multi_Objective_Warehouse_Optimization:\n",
              "MINIMIZE\n",
              "-3.6e-05*hours_ext_Putaway_Afternoon + -4e-05*hours_ext_Putaway_Morning + -3.0000000000000004e-05*hours_ext_Putaway_Night + -5.4e-05*hours_ext_Receiving_Afternoon + -6e-05*hours_ext_Receiving_Morning + -4.500000000000001e-05*hours_ext_Receiving_Night + 1.5500000000000018e-05*ot_hours_perm_Putaway_Afternoon + 5.000000000000006e-06*ot_hours_perm_Putaway_Morning + 3.1250000000000014e-05*ot_hours_perm_Putaway_Night + 4.250000000000003e-05*ot_hours_perm_Receiving_Afternoon + 2.500000000000001e-05*ot_hours_perm_Receiving_Morning + 6.875000000000002e-05*ot_hours_perm_Receiving_Night + -6.699999999999999e-05*reg_hours_perm_Putaway_Afternoon + -7e-05*reg_hours_perm_Putaway_Morning + -6.25e-05*reg_hours_perm_Putaway_Night + -9.499999999999998e-05*reg_hours_perm_Receiving_Afternoon + -9.999999999999999e-05*reg_hours_perm_Receiving_Morning + -8.749999999999999e-05*reg_hours_perm_Receiving_Night + 0.0\n",
              "VARIABLES\n",
              "hours_ext_Putaway_Afternoon Continuous\n",
              "hours_ext_Putaway_Morning Continuous\n",
              "hours_ext_Putaway_Night Continuous\n",
              "hours_ext_Receiving_Afternoon Continuous\n",
              "hours_ext_Receiving_Morning Continuous\n",
              "hours_ext_Receiving_Night Continuous\n",
              "ot_hours_perm_Putaway_Afternoon Continuous\n",
              "ot_hours_perm_Putaway_Morning Continuous\n",
              "ot_hours_perm_Putaway_Night Continuous\n",
              "ot_hours_perm_Receiving_Afternoon Continuous\n",
              "ot_hours_perm_Receiving_Morning Continuous\n",
              "ot_hours_perm_Receiving_Night Continuous\n",
              "reg_hours_perm_Putaway_Afternoon Continuous\n",
              "reg_hours_perm_Putaway_Morning Continuous\n",
              "reg_hours_perm_Putaway_Night Continuous\n",
              "reg_hours_perm_Receiving_Afternoon Continuous\n",
              "reg_hours_perm_Receiving_Morning Continuous\n",
              "reg_hours_perm_Receiving_Night Continuous"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y01vpDvk-9YR"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def optimize_labour_cost(requirements, cost_per_worker):\n",
        "    prob = LpProblem(\"Minimize_Labor_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    vars = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective\n",
        "    prob += lpSum([cost_per_worker[task] * vars[task] for task in vars])\n",
        "    prob.solve()\n",
        "\n",
        "    return {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: vars[task].varValue for task in vars}\n",
        "    }\n",
        "\n",
        "@tool\n",
        "def optimize_labor(input: dict) -> dict:\n",
        "    \"\"\"Optimize labor based on task requirements and cost per task.\"\"\"\n",
        "    return optimize_labour_cost(input[\"requirements\"], input[\"costs\"])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "if abs((weight_cost + weight_productivity + weight_overtime) - 1.0) > 0.001:\n",
        "    raise ValueError(\"Weights must sum to 1.0\")"
      ],
      "metadata": {
        "id": "NcYAU3RyF_9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "o2XAtZQaGLH-",
        "outputId": "e418dfdb-61ce-4934-de0e-10383ef0a62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pulp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-375916748.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpulp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLpProblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpMinimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpSum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpStatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pulp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  # -------------------------------Inputs----------------------------------------------------\n",
        "inputs={'weights':\n",
        "        {'weight_cost':0.5,\n",
        "         'weight_productivity':0.3,\n",
        "         'weight_overtime':0.2},\n",
        "        'shifts':\n",
        "        ['Morning', 'Afternoon', 'Night'],\n",
        "        'skillsets':\n",
        "        ['b2b pickup', 'b2c pickup'],\n",
        "        'permanent_employees' :\n",
        "        {'b2b pickup': 15,'b2c pickup': 12},\n",
        "        'hourly_cost' :\n",
        "        {('Permanent', 'b2b pickup'): 5, ('Permanent', 'b2c pickup'): 3, ('External', 'b2b pickup'): 6, ('External', 'b2c pickup'): 4},\n",
        "        'shift_premium' :\n",
        "        {'Morning': 1.0,'Afternoon': 1.1,'Night': 1.25},\n",
        "        'overtime_premium' :1.5,  # 50% premium for overtime hours\n",
        "        'hours_per_shift' : 8,\n",
        "        'max_regular_hours_per_week' : 40,\n",
        "        'productivity_rate' :\n",
        "        {('Permanent', 'b2b pickup'): 15,  ('Permanent', 'b2c pickup'): 10,('External', 'b2b pickup'): 12,  ('External', 'b2c pickup'): 8  },\n",
        "         'demand' :\n",
        "        {'Morning': 550,'Afternoon': 600, 'Night': 400},\n",
        "        'min_workload' :\n",
        "        {('b2b pickup', 'Morning'): 300,('b2b pickup', 'Afternoon'): 400,('b2b pickup', 'Night'): 100,('b2c pickup', 'Morning'): 300,\n",
        "         ('b2c pickup', 'Afternoon'): 400,('b2c pickup', 'Night'): 300},\n",
        "        'max_external_hires' :\n",
        "         {'b2b pickup': 20,'b2c pickup': 15}}"
      ],
      "metadata": {
        "id": "tgSXSbtm5bPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x1SwcWNGe1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "# from langgraph.prebuilt import create_react_agent\n",
        "# from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "def optimize_labour_cost(requirements, cost_per_worker):\n",
        "\n",
        "    # Create the model\n",
        "    model = pulp.LpProblem(\"Multi_Objective_Warehouse_Optimization\", pulp.LpMinimize)\n",
        "\n",
        "    # Decision Variables\n",
        "\n",
        "    # 1. Regular hours worked by permanent employees\n",
        "    regular_hours_permanent = {}\n",
        "    for skillset in skillsets:\n",
        "      for shift in shifts:\n",
        "          regular_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "              f\"reg_hours_perm_{skillset}_{shift}\",\n",
        "              lowBound=0,\n",
        "              cat='Continuous'\n",
        "          )\n",
        "\n",
        "    # 2. Overtime hours worked by permanent employees\n",
        "    overtime_hours_permanent = {}\n",
        "    for skillset in skillsets:\n",
        "      for shift in shifts:\n",
        "          overtime_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "              f\"ot_hours_perm_{skillset}_{shift}\",\n",
        "              lowBound=0,\n",
        "              cat='Continuous'\n",
        "          )\n",
        "\n",
        "    # 3. Hours worked by external hires (no overtime for external hires in this model)\n",
        "    hours_external = {}\n",
        "    for skillset in skillsets:\n",
        "      for shift in shifts:\n",
        "          hours_external[(skillset, shift)] = pulp.LpVariable(\n",
        "              f\"hours_ext_{skillset}_{shift}\",\n",
        "              lowBound=0,\n",
        "              cat='Continuous'\n",
        "          )\n",
        "\n",
        "    # 4. Number of external hires\n",
        "    external_hires = {}\n",
        "    for skillset in skillsets:\n",
        "      external_hires[skillset] = pulp.LpVariable(\n",
        "          f\"ext_hires_{skillset}\",\n",
        "          lowBound=0,\n",
        "          cat='Integer'\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ====== OBJECTIVE FUNCTIONS ======\n",
        "\n",
        "    # 1. Total Labor Cost (to minimize)\n",
        "    total_cost = pulp.lpSum(\n",
        "        # Cost of regular hours for permanent employees\n",
        "        regular_hours_permanent[(skillset, shift)] *\n",
        "        hourly_cost[('Permanent', skillset)] *\n",
        "        shift_premium[shift]\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    ) + pulp.lpSum(\n",
        "        # Cost of overtime hours for permanent employees\n",
        "        overtime_hours_permanent[(skillset, shift)] *\n",
        "        hourly_cost[('Permanent', skillset)] *\n",
        "        shift_premium[shift] *\n",
        "        overtime_premium\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    ) + pulp.lpSum(\n",
        "        # Cost of external hires\n",
        "        hours_external[(skillset, shift)] *\n",
        "        hourly_cost[('External', skillset)] *\n",
        "        shift_premium[shift]\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    )\n",
        "\n",
        "    # 2. Productivity (to maximize, so we negate it for minimization problem)\n",
        "    total_productivity = pulp.lpSum(\n",
        "        # Productivity from permanent employees\n",
        "        (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "        productivity_rate[('Permanent', skillset)]\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    ) + pulp.lpSum(\n",
        "        # Productivity from external hires\n",
        "        hours_external[(skillset, shift)] *\n",
        "        productivity_rate[('External', skillset)]\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    )\n",
        "\n",
        "    # 3. Overtime cost (to minimize)\n",
        "    overtime_cost = pulp.lpSum(\n",
        "        overtime_hours_permanent[(skillset, shift)] *\n",
        "        hourly_cost[('Permanent', skillset)] *\n",
        "        shift_premium[shift] *\n",
        "        overtime_premium\n",
        "        for skillset in skillsets\n",
        "        for shift in shifts\n",
        "    )\n",
        "\n",
        "\n",
        "    # ---------------------------------------------------------------\n",
        "\n",
        "    # Normalize the objectives for proper weighting\n",
        "    # We'll use estimated maximum values based on the problem context\n",
        "    max_cost_estimate = 50000  # Estimated max possible cost\n",
        "    max_productivity_estimate = 30000  # Estimated max possible productivity\n",
        "    max_overtime_cost_estimate = 15000  # Estimated max overtime cost\n",
        "\n",
        "    normalized_cost = total_cost / max_cost_estimate\n",
        "    normalized_productivity = total_productivity / max_productivity_estimate\n",
        "    normalized_overtime = overtime_cost / max_overtime_cost_estimate\n",
        "\n",
        "    # Combined multi-objective function with weights\n",
        "    model += (\n",
        "        weight_cost * normalized_cost -\n",
        "        weight_productivity * normalized_productivity +\n",
        "        weight_overtime * normalized_overtime\n",
        "    )\n",
        "\n",
        "    # ====== CONSTRAINTS ======\n",
        "\n",
        "    # Constraint 1: Meet minimum workload requirements\n",
        "    for skillset in skillsets:\n",
        "        for shift in shifts:\n",
        "            model += (\n",
        "                regular_hours_permanent[(skillset, shift)] +\n",
        "                overtime_hours_permanent[(skillset, shift)] +\n",
        "                hours_external[(skillset, shift)] >= min_workload[(skillset, shift)],\n",
        "                f\"Min_Workload_{skillset}_{shift}\"\n",
        "            )\n",
        "\n",
        "    # Constraint 2: Total available permanent employees per skillset\n",
        "    for skillset in skillsets:\n",
        "        available_hours_per_week = permanent_employees[skillset] * max_regular_hours_per_week\n",
        "        model += (\n",
        "            pulp.lpSum(regular_hours_permanent[(skillset, shift)] for shift in shifts) <= available_hours_per_week,\n",
        "            f\"Available_Regular_Hours_{skillset}\"\n",
        "        )\n",
        "\n",
        "    # Constraint 3: Maximum number of external hires\n",
        "    for skillset in skillsets:\n",
        "        model += (\n",
        "            external_hires[skillset] <= max_external_hires[skillset],\n",
        "            f\"Max_External_Hires_{skillset}\"\n",
        "        )\n",
        "\n",
        "    # Constraint 4: External hours are limited by number of external hires\n",
        "    for skillset in skillsets:\n",
        "        for shift in shifts:\n",
        "            model += (\n",
        "                hours_external[(skillset, shift)] <= external_hires[skillset] * hours_per_shift,\n",
        "                f\"External_Hours_Limit_{skillset}_{shift}\"\n",
        "            )\n",
        "\n",
        "    # Constraint 5: Total productivity must meet demand for each shift\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            pulp.lpSum(\n",
        "                (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "                productivity_rate[('Permanent', skillset)]\n",
        "                for skillset in skillsets\n",
        "            ) +\n",
        "            pulp.lpSum(\n",
        "                hours_external[(skillset, shift)] * productivity_rate[('External', skillset)]\n",
        "                for skillset in skillsets\n",
        "            ) >= demand[shift],\n",
        "            f\"Meet_Demand_{shift}\"\n",
        "        )\n",
        "\n",
        "      # ====== SOLVE THE MODEL ======\n",
        "    model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
        "\n",
        "    # ====== RESULTS ======\n",
        "    print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
        "\n",
        "    if model.status != pulp.LpStatusOptimal:\n",
        "        print(\"Model did not find an optimal solution.\")\n",
        "        return None\n",
        "\n",
        "    # Calculate the actual values of each objective\n",
        "    actual_cost = pulp.value(total_cost)\n",
        "    actual_productivity = pulp.value(total_productivity)\n",
        "    # actual_overtime_cost = pulp.value(overtime_cost)\n",
        "\n",
        "    print(f\"Total Labor Cost: ${actual_cost:.2f}\")\n",
        "    print(f\"Total Productivity (units): {actual_productivity:.0f}\")\n",
        "    # print(f\"Total Overtime Cost: ${actual_overtime_cost:.2f}\")\n",
        "\n",
        "    # Prepare results\n",
        "    results = []\n",
        "\n",
        "    # Process permanent employee results\n",
        "    for skillset in skillsets:\n",
        "        for shift in shifts:\n",
        "            reg_hours = pulp.value(regular_hours_permanent[(skillset, shift)])\n",
        "            ot_hours = pulp.value(overtime_hours_permanent[(skillset, shift)])\n",
        "\n",
        "            if reg_hours > 0 or ot_hours > 0:\n",
        "                reg_cost = reg_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift]\n",
        "                ot_cost = ot_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift] * overtime_premium\n",
        "                productivity = (reg_hours + ot_hours) * productivity_rate[('Permanent', skillset)]\n",
        "\n",
        "                results.append({\n",
        "                    'Skillset': skillset,\n",
        "                    'Shift': shift,\n",
        "                    'Worker Type': 'Permanent',\n",
        "                    'Regular Hours': reg_hours,\n",
        "                    'Overtime Hours': ot_hours,\n",
        "                    'Total Hours': reg_hours + ot_hours,\n",
        "                    'Regular Cost': reg_cost,\n",
        "                    'Overtime Cost': ot_cost,\n",
        "                    'Total Cost': reg_cost + ot_cost,\n",
        "                    'Productivity': productivity\n",
        "                })\n",
        "\n",
        "    # Process external hire results\n",
        "    for skillset in skillsets:\n",
        "        ext_hired = pulp.value(external_hires[skillset])\n",
        "\n",
        "        for shift in shifts:\n",
        "            ext_hours = pulp.value(hours_external[(skillset, shift)])\n",
        "\n",
        "            if ext_hours > 0:\n",
        "                ext_cost = ext_hours * hourly_cost[('External', skillset)] * shift_premium[shift]\n",
        "                productivity = ext_hours * productivity_rate[('External', skillset)]\n",
        "\n",
        "                results.append({\n",
        "                    'Skillset': skillset,\n",
        "                    'Shift': shift,\n",
        "                    'Worker Type': 'External',\n",
        "                    'Regular Hours': ext_hours,\n",
        "                    'Overtime Hours': 0,\n",
        "                    'Total Hours': ext_hours,\n",
        "                    'Regular Cost': ext_cost,\n",
        "                    'Overtime Cost': 0,\n",
        "                    'Total Cost': ext_cost,\n",
        "                    'Productivity': productivity\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "@tool\n",
        "def optimize_labor(input: dict) -> dict:\n",
        "    \"\"\"Optimize labor based on task requirements and cost per task.\"\"\"\n",
        "    return optimize_labour_cost(input[\"requirements\"], input[\"costs\"])\n"
      ],
      "metadata": {
        "id": "oMPcVRdOk53W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "import pulp\n",
        "model = pulp.LpProblem(\"Multi_Objective_Warehouse_Optimization\", pulp.LpMinimize)\n",
        "\n",
        "# Decision Variables\n",
        "\n",
        "# 1. Regular hours worked by permanent employees\n",
        "regular_hours_permanent = {}\n",
        "for skillset in skillsets:\n",
        "  for shift in shifts:\n",
        "      regular_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "          f\"reg_hours_perm_{skillset}_{shift}\",\n",
        "          lowBound=0,\n",
        "          cat='Continuous'\n",
        "      )\n",
        "\n",
        "# 2. Overtime hours worked by permanent employees\n",
        "overtime_hours_permanent = {}\n",
        "for skillset in skillsets:\n",
        "  for shift in shifts:\n",
        "      overtime_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "          f\"ot_hours_perm_{skillset}_{shift}\",\n",
        "          lowBound=0,\n",
        "          cat='Continuous'\n",
        "      )\n",
        "\n",
        "# 3. Hours worked by external hires (no overtime for external hires in this model)\n",
        "hours_external = {}\n",
        "for skillset in skillsets:\n",
        "  for shift in shifts:\n",
        "      hours_external[(skillset, shift)] = pulp.LpVariable(\n",
        "          f\"hours_ext_{skillset}_{shift}\",\n",
        "          lowBound=0,\n",
        "          cat='Continuous'\n",
        "      )\n",
        "\n",
        "# 4. Number of external hires\n",
        "external_hires = {}\n",
        "for skillset in skillsets:\n",
        "  external_hires[skillset] = pulp.LpVariable(\n",
        "      f\"ext_hires_{skillset}\",\n",
        "      lowBound=0,\n",
        "      cat='Integer'\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        " # ====== OBJECTIVE FUNCTIONS ======\n",
        "\n",
        "# 1. Total Labor Cost (to minimize)\n",
        "total_cost = pulp.lpSum(\n",
        "    # Cost of regular hours for permanent employees\n",
        "    regular_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of overtime hours for permanent employees\n",
        "    overtime_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift] *\n",
        "    overtime_premium\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    hourly_cost[('External', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# 2. Productivity (to maximize, so we negate it for minimization problem)\n",
        "total_productivity = pulp.lpSum(\n",
        "    # Productivity from permanent employees\n",
        "    (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "    productivity_rate[('Permanent', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Productivity from external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    productivity_rate[('External', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# 3. Overtime cost (to minimize)\n",
        "overtime_cost = pulp.lpSum(\n",
        "    overtime_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift] *\n",
        "    overtime_premium\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "NVDUew_TDwoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # ====== CONSTRAINTS ======\n",
        "\n",
        "# Constraint 1: Meet minimum workload requirements\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            regular_hours_permanent[(skillset, shift)] +\n",
        "            overtime_hours_permanent[(skillset, shift)] +\n",
        "            hours_external[(skillset, shift)] >= min_workload[(skillset, shift)],\n",
        "            f\"Min_Workload_{skillset}_{shift}\"\n",
        "        )\n",
        "\n",
        "# Constraint 2: Total available permanent employees per skillset\n",
        "for skillset in skillsets:\n",
        "    available_hours_per_week = permanent_employees[skillset] * max_regular_hours_per_week\n",
        "    model += (\n",
        "        pulp.lpSum(regular_hours_permanent[(skillset, shift)] for shift in shifts) <= available_hours_per_week,\n",
        "        f\"Available_Regular_Hours_{skillset}\"\n",
        "    )\n",
        "\n",
        "# Constraint 3: Maximum number of external hires\n",
        "for skillset in skillsets:\n",
        "    model += (\n",
        "        external_hires[skillset] <= max_external_hires[skillset],\n",
        "        f\"Max_External_Hires_{skillset}\"\n",
        "    )\n",
        "\n",
        "# Constraint 4: External hours are limited by number of external hires\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            hours_external[(skillset, shift)] <= external_hires[skillset] * hours_per_shift,\n",
        "            f\"External_Hours_Limit_{skillset}_{shift}\"\n",
        "        )\n",
        "\n",
        "# Constraint 5: Total productivity must meet demand for each shift\n",
        "for shift in shifts:\n",
        "    model += (\n",
        "        pulp.lpSum(\n",
        "            (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "            productivity_rate[('Permanent', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) +\n",
        "        pulp.lpSum(\n",
        "            hours_external[(skillset, shift)] * productivity_rate[('External', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) >= demand[shift],\n",
        "        f\"Meet_Demand_{shift}\"\n",
        "    )\n",
        "\n",
        "  # ====== SOLVE THE MODEL ======\n",
        "model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
        "\n",
        "# ====== RESULTS ======\n",
        "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
        "\n",
        "# if model.status != pulp.LpStatusOptimal:\n",
        "#     print(\"Model did not find an optimal solution.\")\n",
        "#     return None\n",
        "\n",
        "# Calculate the actual values of each objective\n",
        "actual_cost = pulp.value(total_cost)\n",
        "actual_productivity = pulp.value(total_productivity)\n",
        "# actual_overtime_cost = pulp.value(overtime_cost)\n",
        "\n",
        "print(f\"Total Labor Cost: ${actual_cost:.2f}\")\n",
        "print(f\"Total Productivity (units): {actual_productivity:.0f}\")\n",
        "# print(f\"Total Overtime Cost: ${actual_overtime_cost:.2f}\")\n",
        "\n",
        "# Prepare results\n",
        "results = []\n",
        "\n",
        "# Process permanent employee results\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        reg_hours = pulp.value(regular_hours_permanent[(skillset, shift)])\n",
        "        ot_hours = pulp.value(overtime_hours_permanent[(skillset, shift)])\n",
        "\n",
        "        if reg_hours > 0 or ot_hours > 0:\n",
        "            reg_cost = reg_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift]\n",
        "            ot_cost = ot_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift] * overtime_premium\n",
        "            productivity = (reg_hours + ot_hours) * productivity_rate[('Permanent', skillset)]\n",
        "\n",
        "            results.append({\n",
        "                'Skillset': skillset,\n",
        "                'Shift': shift,\n",
        "                'Worker Type': 'Permanent',\n",
        "                'Regular Hours': reg_hours,\n",
        "                'Overtime Hours': ot_hours,\n",
        "                'Total Hours': reg_hours + ot_hours,\n",
        "                'Regular Cost': reg_cost,\n",
        "                'Overtime Cost': ot_cost,\n",
        "                'Total Cost': reg_cost + ot_cost,\n",
        "                'Productivity': productivity\n",
        "            })\n",
        "\n",
        "# Process external hire results\n",
        "for skillset in skillsets:\n",
        "    ext_hired = pulp.value(external_hires[skillset])\n",
        "\n",
        "    for shift in shifts:\n",
        "        ext_hours = pulp.value(hours_external[(skillset, shift)])\n",
        "\n",
        "        if ext_hours > 0:\n",
        "            ext_cost = ext_hours * hourly_cost[('External', skillset)] * shift_premium[shift]\n",
        "            productivity = ext_hours * productivity_rate[('External', skillset)]\n",
        "\n",
        "            results.append({\n",
        "                'Skillset': skillset,\n",
        "                'Shift': shift,\n",
        "                'Worker Type': 'External',\n",
        "                'Regular Hours': ext_hours,\n",
        "                'Overtime Hours': 0,\n",
        "                'Total Hours': ext_hours,\n",
        "                'Regular Cost': ext_cost,\n",
        "                'Overtime Cost': 0,\n",
        "                'Total Cost': ext_cost,\n",
        "                'Productivity': productivity\n",
        "            })\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7lY7mO0-BQa",
        "outputId": "bf30fc8f-0ab7-4e4e-d599-d9e382bd2158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status: Optimal\n",
            "Total Labor Cost: $11062.50\n",
            "Total Productivity (units): 20740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "  # -------------------------------Inputs----------------------------------------------------\n",
        "\n",
        "weight_cost=0.5\n",
        "weight_productivity=0.3\n",
        "# weight_overtime=0.2\n",
        "\n",
        "if abs((weight_cost + weight_productivity ) - 1.0) > 0.001:\n",
        "    raise ValueError(\"Weights must sum to 1.0\")\n",
        "  # Define shifts\n",
        "shifts = ['Morning', 'Afternoon', 'Night']\n",
        "\n",
        "# Define skillsets\n",
        "skillsets = ['b2b pickup', 'b2c pickup']\n",
        "\n",
        "# Fixed number of permanent employees per skillset\n",
        "permanent_employees = {\n",
        "    'b2b pickup': 15,\n",
        "    'b2c pickup': 12\n",
        "}\n",
        "\n",
        "# Cost parameters\n",
        "hourly_cost = {\n",
        "    # Regular hourly cost for permanent employees\n",
        "    ('Permanent', 'b2b pickup'): 5,\n",
        "    ('Permanent', 'b2c pickup'): 3,\n",
        "    # Higher costs for external hires\n",
        "    ('External', 'b2b pickup'): 6,\n",
        "    ('External', 'b2c pickup'): 4\n",
        "}\n",
        "\n",
        "# Shift premiums (multipliers applied to base hourly cost)\n",
        "shift_premium = {\n",
        "    'Morning': 1.0,    # No premium\n",
        "    'Afternoon': 1.1,  # 10% premium\n",
        "    'Night': 1.25      # 25% premium\n",
        "}\n",
        "\n",
        "# Overtime premiums (applied when workers exceed regular hours)\n",
        "overtime_premium = 1.5  # 50% premium for overtime hours\n",
        "\n",
        "# Hours per shift\n",
        "hours_per_shift = 8\n",
        "\n",
        "# Maximum regular hours per employee per week (to track overtime)\n",
        "max_regular_hours_per_week = 40\n",
        "\n",
        "# Productivity rates per skillset (units processed per hour)\n",
        "productivity_rate = {\n",
        "    ('Permanent', 'b2b pickup'): 15,  # Permanent employees are more productive\n",
        "    ('Permanent', 'b2c pickup'): 10,\n",
        "    ('External', 'b2b pickup'): 12,  # External hires are less productive\n",
        "    ('External', 'b2c pickup'): 8\n",
        "}\n",
        "\n",
        "# Workload demand (in units to be processed) for each shift\n",
        "demand = {\n",
        "    'Morning': 550,\n",
        "    'Afternoon': 600,\n",
        "    'Night': 400\n",
        "}\n",
        "\n",
        "# Minimum workload requirements (in labor-hours) for each skillset and shift\n",
        "min_workload = {\n",
        "    ('b2b pickup', 'Morning'): 300,\n",
        "    ('b2b pickup', 'Afternoon'): 400,\n",
        "    ('b2b pickup', 'Night'): 100,\n",
        "    ('b2c pickup', 'Morning'): 300,\n",
        "    ('b2c pickup', 'Afternoon'): 400,\n",
        "    ('b2c pickup', 'Night'): 300\n",
        "}\n",
        "\n",
        "# Maximum number of external hires per skillset (resource constraint)\n",
        "max_external_hires = {\n",
        "    'b2b pickup': 20,\n",
        "    'b2c pickup': 15\n",
        "}"
      ],
      "metadata": {
        "id": "Pj1wHoil6MjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # ====== SOLVE THE MODEL ======\n",
        "    model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
        "\n",
        "    # ====== RESULTS ======\n",
        "    print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
        "\n",
        "    if model.status != pulp.LpStatusOptimal:\n",
        "        print(\"Model did not find an optimal solution.\")\n",
        "        return None\n",
        "\n",
        "    # Calculate the actual values of each objective\n",
        "    actual_cost = pulp.value(total_cost)\n",
        "    actual_productivity = pulp.value(total_productivity)\n",
        "    # actual_overtime_cost = pulp.value(overtime_cost)\n",
        "\n",
        "    print(f\"Total Labor Cost: ${actual_cost:.2f}\")\n",
        "    print(f\"Total Productivity (units): {actual_productivity:.0f}\")\n",
        "    # print(f\"Total Overtime Cost: ${actual_overtime_cost:.2f}\")\n",
        "\n",
        "    # Prepare results\n",
        "    results = []\n",
        "\n",
        "    # Process permanent employee results\n",
        "    for skillset in skillsets:\n",
        "        for shift in shifts:\n",
        "            reg_hours = pulp.value(regular_hours_permanent[(skillset, shift)])\n",
        "            ot_hours = pulp.value(overtime_hours_permanent[(skillset, shift)])\n",
        "\n",
        "            if reg_hours > 0 or ot_hours > 0:\n",
        "                reg_cost = reg_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift]\n",
        "                ot_cost = ot_hours * hourly_cost[('Permanent', skillset)] * shift_premium[shift] * overtime_premium\n",
        "                productivity = (reg_hours + ot_hours) * productivity_rate[('Permanent', skillset)]\n",
        "\n",
        "                results.append({\n",
        "                    'Skillset': skillset,\n",
        "                    'Shift': shift,\n",
        "                    'Worker Type': 'Permanent',\n",
        "                    'Regular Hours': reg_hours,\n",
        "                    'Overtime Hours': ot_hours,\n",
        "                    'Total Hours': reg_hours + ot_hours,\n",
        "                    'Regular Cost': reg_cost,\n",
        "                    'Overtime Cost': ot_cost,\n",
        "                    'Total Cost': reg_cost + ot_cost,\n",
        "                    'Productivity': productivity\n",
        "                })\n",
        "\n",
        "    # Process external hire results\n",
        "    for skillset in skillsets:\n",
        "        ext_hired = pulp.value(external_hires[skillset])\n",
        "\n",
        "        for shift in shifts:\n",
        "            ext_hours = pulp.value(hours_external[(skillset, shift)])\n",
        "\n",
        "            if ext_hours > 0:\n",
        "                ext_cost = ext_hours * hourly_cost[('External', skillset)] * shift_premium[shift]\n",
        "                productivity = ext_hours * productivity_rate[('External', skillset)]\n",
        "\n",
        "                results.append({\n",
        "                    'Skillset': skillset,\n",
        "                    'Shift': shift,\n",
        "                    'Worker Type': 'External',\n",
        "                    'Regular Hours': ext_hours,\n",
        "                    'Overtime Hours': 0,\n",
        "                    'Total Hours': ext_hours,\n",
        "                    'Regular Cost': ext_cost,\n",
        "                    'Overtime Cost': 0,\n",
        "                    'Total Cost': ext_cost,\n",
        "                    'Productivity': productivity\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate headcount from hours\n",
        "    results_df['Headcount'] = (results_df['Total Hours'] / hours_per_shift).round(1)\n",
        "\n",
        "    # Summary of external hires\n",
        "    external_summary = {}\n",
        "    for skillset in skillsets:\n",
        "        external_summary[skillset] = pulp.value(external_hires[skillset])\n",
        "\n",
        "    print(\"\\nOptimal Solution Summary:\")\n",
        "    print(results_df[['Skillset', 'Shift', 'Worker Type', 'Headcount', 'Regular Hours',\n",
        "                      'Overtime Hours', 'Total Cost', 'Productivity']])\n",
        "\n",
        "    print(\"\\nExternal Hires Required:\")\n",
        "    for skillset, count in external_summary.items():\n",
        "        print(f\"{skillset}: {int(count)}\")\n",
        "\n",
        "    # Calculate totals by skillset\n",
        "    skillset_summary = results_df.groupby('Skillset').agg({\n",
        "        'Headcount': 'sum',\n",
        "        'Regular Hours': 'sum',\n",
        "        'Overtime Hours': 'sum',\n",
        "        'Total Cost': 'sum',\n",
        "        'Productivity': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    print(\"\\nSummary by Skillset:\")\n",
        "    print(skillset_summary)\n",
        "\n",
        "    # Calculate totals by shift\n",
        "    shift_summary = results_df.groupby('Shift').agg({\n",
        "        'Headcount': 'sum',\n",
        "        'Regular Hours': 'sum',\n",
        "        'Overtime Hours': 'sum',\n",
        "        'Total Cost': 'sum',\n",
        "        'Productivity': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    print(\"\\nSummary by Shift:\")\n",
        "    print(shift_summary)\n",
        "\n",
        "    # Calculate totals by worker type\n",
        "    type_summary = results_df.groupby('Worker Type').agg({\n",
        "        'Headcount': 'sum',\n",
        "        'Regular Hours': 'sum',\n",
        "        'Overtime Hours': 'sum',\n",
        "        'Total Cost': 'sum',\n",
        "        'Productivity': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    print(\"\\nSummary by Worker Type:\")\n",
        "    print(type_summary)\n"
      ],
      "metadata": {
        "id": "zIeBLFfp3TZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVfYCKY6DExB"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEkrwtjqCTMI"
      },
      "outputs": [],
      "source": [
        "\n",
        "system_prompt = SystemMessage(\n",
        "    \"\"\"You are a Math Expert who can solve any math problem.\n",
        "    Solve the problems provided by user, by using only tools available.\n",
        "    Compute opimum value of requirement of labour for every task\"\"\"\n",
        ")\n",
        "\n",
        "tools = [optimize_labor]\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "agent_graph= create_react_agent(\n",
        "    model=model,\n",
        "    prompt=system_prompt,\n",
        "    tools=tools\n",
        "    )\n",
        "# Example 1\n",
        "input = {\"messages\":\"\"\"{\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"b2c pickup\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"b2c pickup\": 110}\n",
        "\"\"\"\n",
        "}\n",
        "result = agent_graph.invoke(input)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJ6vL0Vn3OAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODKXkDWTGOh3",
        "outputId": "54be045d-a626-4753-badc-db8f240771be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Result: The optimal number of labors for unloading, scanning, and putaway are 3, 2, and 4, respectively. The total cost is 920. \n",
            "\n",
            "Step by step execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "{\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"putaway\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"putaway\": 110}\n",
            "\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  optimize_labor (8f7e6584-5093-4ad0-8389-ddd5cac935c5)\n",
            " Call ID: 8f7e6584-5093-4ad0-8389-ddd5cac935c5\n",
            "  Args:\n",
            "    input: {\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"putaway\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"putaway\": 110}}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labor\n",
            "\n",
            "Error: 1 validation error for optimize_labor\n",
            "input\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"requirements\": {\"unloa...g\": 90,\"putaway\": 110}}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I am unable to provide a direct answer with the current tool. The tool requires a dictionary as input, but it seems I am sending a string. I will reformat the input.\n",
            "Tool Calls:\n",
            "  optimize_labor (cc8f1cb9-1c7b-4d8b-aa2c-28854dde15ab)\n",
            " Call ID: cc8f1cb9-1c7b-4d8b-aa2c-28854dde15ab\n",
            "  Args:\n",
            "    input: {'requirements': {'scanning': [2.0, 6.0], 'putaway': [4.0, 10.0], 'unloading': [3.0, 8.0]}, 'costs': {'scanning': 90.0, 'putaway': 110.0, 'unloading': 100.0}}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labor\n",
            "\n",
            "{\"status\": \"Optimal\", \"objective\": 920.0, \"assignment\": {\"scanning\": 2.0, \"putaway\": 4.0, \"unloading\": 3.0}}\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "The optimal number of labors for unloading, scanning, and putaway are 3, 2, and 4, respectively. The total cost is 920.\n"
          ]
        }
      ],
      "source": [
        "# Get the final result\n",
        "print(f\"Final Result: {result['messages'][-1].content} \\n\")\n",
        "\n",
        "print(\"Step by step execution\")\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_repr())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kaUI3Dic2PpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6L0h864R2O"
      },
      "source": [
        "## Code - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecdwy1Chqo41"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def optimize_labour_cost(requirements, cost_per_worker):\n",
        "    prob = LpProblem(\"Minimize_Labor_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    vars = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective\n",
        "    prob += lpSum([cost_per_worker[task] * vars[task] for task in vars])\n",
        "    prob.solve()\n",
        "\n",
        "    return {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: vars[task].varValue for task in vars}\n",
        "    }\n",
        "\n",
        "\n",
        "@tool\n",
        "def optimize_labor(input: str) -> str:\n",
        "    \"\"\"You can parse input to structured data here (dummy example below) \"\"\"\n",
        "    requirements = {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"b2c pickup\": (4, 10)\n",
        "    }\n",
        "    costs = {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"b2c pickup\": 110\n",
        "    }\n",
        "\n",
        "    result = optimize_labour_cost(requirements, costs)\n",
        "    return str(result)\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n",
        "\n",
        "tools = [optimize_labor]\n",
        "agent_node = create_react_agent(model=model, tools=tools)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nu1gRKXIqo42"
      },
      "outputs": [],
      "source": [
        "# Wrap the agent_node with a callable\n",
        "agent_graph = RunnableLambda(lambda state: {\n",
        "    \"requirements\": state[\"requirements\"],\n",
        "    \"costs\" :state[\"cost\"],\n",
        "    \"output\": agent_node.invoke(state[\"prompt\"]).content\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7OItd8f4U30"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "     requirements: dict\n",
        "     costs: dict\n",
        "     output: str\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"optimize\", agent_graph)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "emTWxAOe-3_P",
        "outputId": "d9f230dd-7893-434b-c80b-794063ef7659"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'cost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-3843899204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m   4771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4772\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4773\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4774\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-16-2020979278.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      2\u001b[0m agent_graph = RunnableLambda(lambda state: {\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"requirements\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requirements\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"costs\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0magent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m })\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cost'"
          ]
        }
      ],
      "source": [
        "initial_state = {\"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"b2c pickup\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"b2c pickup\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ8gcYuVrmCB"
      },
      "outputs": [],
      "source": [
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeU85hWhY4o2"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Agent state: the warehouse parameters\n",
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"b2c pickup\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"b2c pickup\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "# LangGraph node\n",
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "\n",
        "# Create LangGraph\n",
        "graph = StateGraph()\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLlUmnVzYcVh"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA9mKy3jY7QQ"
      },
      "outputs": [],
      "source": [
        "tools = [optimize_labour_cost]\n",
        "\n",
        "# System Prompt\n",
        "system_prompt = SystemMessage(\n",
        "    \"\"\"You are a Math Expert who can solve any math problem.\n",
        "    Solve the problems provided by user, by using only tools available.\n",
        "    Do not solve the problem yourself\"\"\"\n",
        ")\n",
        "\n",
        "# Create the agent\n",
        "agent_node= create_react_agent(\n",
        "    model=model,\n",
        "    prompt=system_prompt,\n",
        "    tools=tools\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hna32arHZT-a",
        "outputId": "43efeb1e-d76d-4799-92a8-b1379d8f056a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Result: I apologize, but it seems I am encountering an error with the tool and am unable to provide a solution at this time. \n",
            "\n",
            "Step by step execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (3f5f33c8-37f6-4c70-b397-d2c990427153)\n",
            " Call ID: 3f5f33c8-37f6-4c70-b397-d2c990427153\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize for the error. It seems I made a mistake in the way I formatted the input. I should have provided a dictionary as a string.\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (2f1440c4-4e88-42bc-bea1-58e5f0bc44f9)\n",
            " Call ID: 2f1440c4-4e88-42bc-bea1-58e5f0bc44f9\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize for the repeated errors. It seems I am having trouble formatting the input correctly. I will try again, ensuring the input is a valid dictionary format.\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (caeac750-0730-4411-a8c4-1c40a2337308)\n",
            " Call ID: caeac750-0730-4411-a8c4-1c40a2337308\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize, but it seems I am encountering an error with the tool and am unable to provide a solution at this time.\n"
          ]
        }
      ],
      "source": [
        "# Example 1\n",
        "input = {\"messages\":[(\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. b2c pickup needs 4 to 6 at $110.\")]}\n",
        "result = agent_node.invoke(input)\n",
        "\n",
        "# Get the final result\n",
        "print(f\"Final Result: {result['messages'][-1].content} \\n\")\n",
        "\n",
        "print(\"Step by step execution\")\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_repr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVEERwig1hYd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KXo6a1U1sor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuRg43rJY8mu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjUypbXqYz_d"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2K2pbGhUJik"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_gv-_8wTjNh"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_experimental\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcygQMhSHO7M"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU \"langchain[anthropic]\" to call the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_EPvo3wj86P",
        "outputId": "a5916592-7889-4671-a2a0-393dd2107b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<AgentType.ZERO_SHOT_REACT_DESCRIPTION: 'zero-shot-react-description'>, <AgentType.REACT_DOCSTORE: 'react-docstore'>, <AgentType.SELF_ASK_WITH_SEARCH: 'self-ask-with-search'>, <AgentType.CONVERSATIONAL_REACT_DESCRIPTION: 'conversational-react-description'>, <AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'chat-zero-shot-react-description'>, <AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION: 'chat-conversational-react-description'>, <AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'structured-chat-zero-shot-react-description'>, <AgentType.OPENAI_FUNCTIONS: 'openai-functions'>, <AgentType.OPENAI_MULTI_FUNCTIONS: 'openai-multi-functions'>]\n"
          ]
        }
      ],
      "source": [
        "print(list(AgentType))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPlTzG4qtbD6"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    prompt: str\n",
        "    output: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wy7X7g_rwVD"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "jaGW6ZBsESaO",
        "outputId": "1ac8b100-a4f6-409f-b1c4-ae14f2f898d9"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Expected a callable type for `func`.Instead got an unsupported type: <class 'langgraph.graph.state.CompiledStateGraph'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2142784406>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, afunc, name)\u001b[0m\n\u001b[1;32m   4401\u001b[0m                 \u001b[0;34mf\"Instead got an unsupported type: {type(func)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4402\u001b[0m             )\n\u001b[0;32m-> 4403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4405\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected a callable type for `func`.Instead got an unsupported type: <class 'langgraph.graph.state.CompiledStateGraph'>"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# def agent_node(state):\n",
        "#     prompt = state[\"prompt\"]\n",
        "#     response = agent.run(prompt)\n",
        "#     return {\"output\": response}\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"react_agent\", RunnableLambda(agent_node))\n",
        "graph.set_entry_point(\"react_agent\")\n",
        "graph.add_edge(\"react_agent\", END)\n",
        "\n",
        "app = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "4sg_ZTMvFD22",
        "outputId": "f6d5e710-c3a5-49e8-c4af-ede56729475f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'CompiledStateGraph' object has no attribute 'run'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-567025205>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = app.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\"prompt\":\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\"\n\u001b[1;32m      3\u001b[0m })\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m   4771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4772\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4773\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4774\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-2649617900>\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0magent_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CompiledStateGraph' object has no attribute 'run'"
          ]
        }
      ],
      "source": [
        "response = app.invoke(\n",
        "    {\"prompt\":\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. b2c pickup needs 4 to 6 at $110.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuTGcjT7tY6A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "iw-gpBKbFJum",
        "outputId": "cf470ccc-cab3-4669-d853-09169872ddb1"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-155192096>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#reduce inference cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mabot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-1091725969>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tools, system)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"llm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1091725969>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"llm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
        "abot = Agent(llm, [tool], system=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TVlEZQKkbCw"
      },
      "outputs": [],
      "source": [
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "wDXTZ2Xzp1rn",
        "outputId": "8414671c-9aa8-4741-be53-9cc0c6d8f440"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Must provide state_schema or input and output",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3814180203>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create LangGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_schema, config_schema, input, output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide state_schema or input and output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mstate_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValueError\u001b[0m: Must provide state_schema or input and output"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Agent state: the warehouse parameters\n",
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"b2c pickup\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"b2c pickup\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "# LangGraph node\n",
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "\n",
        "# Create LangGraph\n",
        "graph = StateGraph()\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}