{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhqN6k_C8UDD",
        "outputId": "012d2f68-4555-47b5-f7d7-ab70b1c9fa70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph\n",
        "!pip install transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZvU_NdWUOgYh",
        "outputId": "75c835ed-a1f4-45a9-f1e8-9810892623eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.26 (from langchain_community)\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.45)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.65\n",
            "    Uninstalling langchain-core-0.3.65:\n",
            "      Successfully uninstalled langchain-core-0.3.65\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.26 langchain-core-0.3.66 langchain_community-0.3.26 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.66)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Collecting pulp\n",
            "  Downloading pulp-3.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.66)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Downloading pulp-3.2.1-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-3.2.1\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.66)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "281a47ea328741f98cc3dc0a9c3dab66",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain_experiment (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain_experiment\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install langgraph langchain openai networkx pulp\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain_experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i6rDFnhB5Si"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "# from langchain_experimental.chat_models import HuggingFaceChat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuv1SFNh8rrP"
      },
      "outputs": [],
      "source": [
        "import pulp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVPx5Nww8y5O"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "VktRSeud83Oz",
        "outputId": "02ac8f03-755a-40e9-9cb0-a912284b0e9b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-1866905173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(tool.name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceHub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HUGGINGFACEHUB_API_TOKEN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m llm = HuggingFaceHub(\n\u001b[1;32m     10\u001b[0m     \u001b[0mrepo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistralai/Mistral-7B-Instruct-v0.2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "# os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
        "# tool = TavilySearchResults(max_results=4) #increased number of results\n",
        "# print(type(tool))\n",
        "# # print(tool.name)\n",
        "# from langchain.llms import HuggingFaceHub\n",
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass()\n",
        "# llm = HuggingFaceHub(\n",
        "#     repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "#     model_kwargs={\"temperature\": 0.5, \"max_length\": 64,\"max_new_tokens\":512}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC2NUh3prpAk"
      },
      "source": [
        "### Code -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3HrquhYVjD6"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuA-HUOdprxj"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.prebuilt import create_react_agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLcbD2CGeyL7"
      },
      "outputs": [],
      "source": [
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAM50WbvdaMH",
        "outputId": "ee0e7712-21ce-4639-c35a-e5c5fdf8cbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'status': 'Optimal', 'objective': 920.0, 'assignment': {'unloading': 3.0, 'scanning': 2.0, 'putaway': 4.0}}\n"
          ]
        }
      ],
      "source": [
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"putaway\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"putaway\": 110\n",
        "    }\n",
        "}\n",
        "class AgentState(TypedDict):\n",
        "    requirements: dict\n",
        "    costs: dict\n",
        "    result: dict\n",
        "\n",
        "tools = [optimize_labor]\n",
        "# agent_node = create_react_agent(model=model, tools=tools)\n",
        "# Create LangGraph\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHzYn83s-_UV"
      },
      "source": [
        "## Code -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgSXSbtm5bPr"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "  # -------------------------------Inputs----------------------------------------------------\n",
        "\n",
        "weight_cost=0.5\n",
        "weight_productivity=0.3\n",
        "weight_overtime=0.2\n",
        "\n",
        "if abs((weight_cost + weight_productivity + weight_overtime) - 1.0) > 0.001:\n",
        "    raise ValueError(\"Weights must sum to 1.0\")\n",
        "  # Define shifts\n",
        "shifts = ['Morning', 'Afternoon', 'Night']\n",
        "\n",
        "# Define skillsets\n",
        "skillsets = ['Receiving', 'Putaway']\n",
        "\n",
        "# Fixed number of permanent employees per skillset\n",
        "permanent_employees = {\n",
        "    'Receiving': 15,\n",
        "    'Putaway': 12\n",
        "}\n",
        "\n",
        "# Cost parameters\n",
        "hourly_cost = {\n",
        "    # Regular hourly cost for permanent employees\n",
        "    ('Permanent', 'Receiving'): 5,\n",
        "    ('Permanent', 'Putaway'): 3,\n",
        "    # Higher costs for external hires\n",
        "    ('External', 'Receiving'): 6,\n",
        "    ('External', 'Putaway'): 4\n",
        "}\n",
        "\n",
        "# Shift premiums (multipliers applied to base hourly cost)\n",
        "shift_premium = {\n",
        "    'Morning': 1.0,    # No premium\n",
        "    'Afternoon': 1.1,  # 10% premium\n",
        "    'Night': 1.25      # 25% premium\n",
        "}\n",
        "\n",
        "# Overtime premiums (applied when workers exceed regular hours)\n",
        "overtime_premium = 1.5  # 50% premium for overtime hours\n",
        "\n",
        "# Hours per shift\n",
        "hours_per_shift = 8\n",
        "\n",
        "# Maximum regular hours per employee per week (to track overtime)\n",
        "max_regular_hours_per_week = 40\n",
        "\n",
        "# Productivity rates per skillset (units processed per hour)\n",
        "productivity_rate = {\n",
        "    ('Permanent', 'Receiving'): 15,  # Permanent employees are more productive\n",
        "    ('Permanent', 'Putaway'): 10,\n",
        "    ('External', 'Receiving'): 12,  # External hires are less productive\n",
        "    ('External', 'Putaway'): 8\n",
        "}\n",
        "\n",
        "# Workload demand (in units to be processed) for each shift\n",
        "demand = {\n",
        "    'Morning': 550,\n",
        "    'Afternoon': 600,\n",
        "    'Night': 400\n",
        "}\n",
        "\n",
        "# Minimum workload requirements (in labor-hours) for each skillset and shift\n",
        "min_workload = {\n",
        "    ('Receiving', 'Morning'): 300,\n",
        "    ('Receiving', 'Afternoon'): 400,\n",
        "    ('Receiving', 'Night'): 100,\n",
        "    ('Putaway', 'Morning'): 300,\n",
        "    ('Putaway', 'Afternoon'): 400,\n",
        "    ('Putaway', 'Night'): 300\n",
        "}\n",
        "\n",
        "# Maximum number of external hires per skillset (resource constraint)\n",
        "max_external_hires = {\n",
        "    'Receiving': 20,\n",
        "    'Putaway': 15\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkPsFjE75gLh"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------- Decision variables --------------------------------------------------\n",
        "\n",
        "  # ====== MODEL SETUP ======\n",
        "\n",
        "  # Create the model\n",
        "model = pulp.LpProblem(\"Multi_Objective_Warehouse_Optimization\", pulp.LpMinimize)\n",
        "\n",
        "# Decision Variables\n",
        "\n",
        "# 1. Regular hours worked by permanent employees\n",
        "regular_hours_permanent = {}\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        regular_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "            f\"reg_hours_perm_{skillset}_{shift}\",\n",
        "            lowBound=0,\n",
        "            cat='Continuous'\n",
        "        )\n",
        "\n",
        "# 2. Overtime hours worked by permanent employees\n",
        "overtime_hours_permanent = {}\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        overtime_hours_permanent[(skillset, shift)] = pulp.LpVariable(\n",
        "            f\"ot_hours_perm_{skillset}_{shift}\",\n",
        "            lowBound=0,\n",
        "            cat='Continuous'\n",
        "        )\n",
        "\n",
        "# 3. Hours worked by external hires (no overtime for external hires in this model)\n",
        "hours_external = {}\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        hours_external[(skillset, shift)] = pulp.LpVariable(\n",
        "            f\"hours_ext_{skillset}_{shift}\",\n",
        "            lowBound=0,\n",
        "            cat='Continuous'\n",
        "        )\n",
        "\n",
        "# 4. Number of external hires\n",
        "external_hires = {}\n",
        "for skillset in skillsets:\n",
        "    external_hires[skillset] = pulp.LpVariable(\n",
        "        f\"ext_hires_{skillset}\",\n",
        "        lowBound=0,\n",
        "        cat='Integer'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1gPYv1R3Jxd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ====== OBJECTIVE FUNCTIONS ======\n",
        "\n",
        "# 1. Total Labor Cost (to minimize)\n",
        "total_cost = pulp.lpSum(\n",
        "    # Cost of regular hours for permanent employees\n",
        "    regular_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of overtime hours for permanent employees\n",
        "    overtime_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift] *\n",
        "    overtime_premium\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Cost of external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    hourly_cost[('External', skillset)] *\n",
        "    shift_premium[shift]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# 2. Productivity (to maximize, so we negate it for minimization problem)\n",
        "total_productivity = pulp.lpSum(\n",
        "    # Productivity from permanent employees\n",
        "    (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "    productivity_rate[('Permanent', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ") + pulp.lpSum(\n",
        "    # Productivity from external hires\n",
        "    hours_external[(skillset, shift)] *\n",
        "    productivity_rate[('External', skillset)]\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "# 3. Overtime cost (to minimize)\n",
        "overtime_cost = pulp.lpSum(\n",
        "    overtime_hours_permanent[(skillset, shift)] *\n",
        "    hourly_cost[('Permanent', skillset)] *\n",
        "    shift_premium[shift] *\n",
        "    overtime_premium\n",
        "    for skillset in skillsets\n",
        "    for shift in shifts\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Normalize the objectives for proper weighting\n",
        "# We'll use estimated maximum values based on the problem context\n",
        "max_cost_estimate = 50000  # Estimated max possible cost\n",
        "max_productivity_estimate = 30000  # Estimated max possible productivity\n",
        "max_overtime_cost_estimate = 15000  # Estimated max overtime cost\n",
        "\n",
        "normalized_cost = total_cost / max_cost_estimate\n",
        "normalized_productivity = total_productivity / max_productivity_estimate\n",
        "normalized_overtime = overtime_cost / max_overtime_cost_estimate\n",
        "\n",
        "# Combined multi-objective function with weights\n",
        "model += (\n",
        "    weight_cost * normalized_cost -\n",
        "    weight_productivity * normalized_productivity +\n",
        "    weight_overtime * normalized_overtime\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMp-9jK6yDyK",
        "outputId": "a84dfbd9-615c-4aba-b019-43efd546a4a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Multi_Objective_Warehouse_Optimization:\n",
              "MINIMIZE\n",
              "-3.6e-05*hours_ext_Putaway_Afternoon + -4e-05*hours_ext_Putaway_Morning + -3.0000000000000004e-05*hours_ext_Putaway_Night + -5.4e-05*hours_ext_Receiving_Afternoon + -6e-05*hours_ext_Receiving_Morning + -4.500000000000001e-05*hours_ext_Receiving_Night + 1.5500000000000018e-05*ot_hours_perm_Putaway_Afternoon + 5.000000000000006e-06*ot_hours_perm_Putaway_Morning + 3.1250000000000014e-05*ot_hours_perm_Putaway_Night + 4.250000000000003e-05*ot_hours_perm_Receiving_Afternoon + 2.500000000000001e-05*ot_hours_perm_Receiving_Morning + 6.875000000000002e-05*ot_hours_perm_Receiving_Night + -6.699999999999999e-05*reg_hours_perm_Putaway_Afternoon + -7e-05*reg_hours_perm_Putaway_Morning + -6.25e-05*reg_hours_perm_Putaway_Night + -9.499999999999998e-05*reg_hours_perm_Receiving_Afternoon + -9.999999999999999e-05*reg_hours_perm_Receiving_Morning + -8.749999999999999e-05*reg_hours_perm_Receiving_Night + 0.0\n",
              "VARIABLES\n",
              "hours_ext_Putaway_Afternoon Continuous\n",
              "hours_ext_Putaway_Morning Continuous\n",
              "hours_ext_Putaway_Night Continuous\n",
              "hours_ext_Receiving_Afternoon Continuous\n",
              "hours_ext_Receiving_Morning Continuous\n",
              "hours_ext_Receiving_Night Continuous\n",
              "ot_hours_perm_Putaway_Afternoon Continuous\n",
              "ot_hours_perm_Putaway_Morning Continuous\n",
              "ot_hours_perm_Putaway_Night Continuous\n",
              "ot_hours_perm_Receiving_Afternoon Continuous\n",
              "ot_hours_perm_Receiving_Morning Continuous\n",
              "ot_hours_perm_Receiving_Night Continuous\n",
              "reg_hours_perm_Putaway_Afternoon Continuous\n",
              "reg_hours_perm_Putaway_Morning Continuous\n",
              "reg_hours_perm_Putaway_Night Continuous\n",
              "reg_hours_perm_Receiving_Afternoon Continuous\n",
              "reg_hours_perm_Receiving_Morning Continuous\n",
              "reg_hours_perm_Receiving_Night Continuous"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "694uWRhTzAkv"
      },
      "outputs": [],
      "source": [
        "# Constraint 1: Meet minimum workload requirements\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            regular_hours_permanent[(skillset, shift)] +\n",
        "            overtime_hours_permanent[(skillset, shift)] +\n",
        "            hours_external[(skillset, shift)] >= min_workload[(skillset, shift)],\n",
        "            f\"Min_Workload_{skillset}_{shift}\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2WmJzjvzP9O"
      },
      "outputs": [],
      "source": [
        "# Constraint 5: Total productivity must meet demand for each shift\n",
        "for shift in shifts:\n",
        "    model += (\n",
        "        pulp.lpSum(\n",
        "            (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "            productivity_rate[('Permanent', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) +\n",
        "        pulp.lpSum(\n",
        "            hours_external[(skillset, shift)] * productivity_rate[('External', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) >= demand[shift],\n",
        "        f\"Meet_Demand_{shift}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IPG2oEvm8a25",
        "outputId": "a8e68ed8-3faa-4210-b9c6-25c623cf597c"
      },
      "outputs": [
        {
          "ename": "PulpError",
          "evalue": "overlapping constraint names: Min_Workload_Receiving_Morning",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPulpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-1085368447.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mskillset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskillsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mshift\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         model += (\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mregular_hours_permanent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskillset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0movertime_hours_permanent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskillset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pulp/pulp.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1826\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpConstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpAffineExpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pulp/pulp.py\u001b[0m in \u001b[0;36maddConstraint\u001b[0;34m(self, constraint, name)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoOverlap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPulpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overlapping constraint names: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning: overlapping constraint names:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPulpError\u001b[0m: overlapping constraint names: Min_Workload_Receiving_Morning"
          ]
        }
      ],
      "source": [
        "# ====== CONSTRAINTS ======\n",
        "\n",
        "# Constraint 1: Meet minimum workload requirements\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            regular_hours_permanent[(skillset, shift)] +\n",
        "            overtime_hours_permanent[(skillset, shift)] +\n",
        "            hours_external[(skillset, shift)] >= min_workload[(skillset, shift)],\n",
        "            f\"Min_Workload_{skillset}_{shift}\"\n",
        "        )\n",
        "\n",
        "# Constraint 2: Total available permanent employees per skillset\n",
        "for skillset in skillsets:\n",
        "    available_hours_per_week = permanent_employees[skillset] * max_regular_hours_per_week\n",
        "    model += (\n",
        "        pulp.lpSum(regular_hours_permanent[(skillset, shift)] for shift in shifts) <= available_hours_per_week,\n",
        "        f\"Available_Regular_Hours_{skillset}\"\n",
        "    )\n",
        "\n",
        "# Constraint 3: Maximum number of external hires\n",
        "for skillset in skillsets:\n",
        "    model += (\n",
        "        external_hires[skillset] <= max_external_hires[skillset],\n",
        "        f\"Max_External_Hires_{skillset}\"\n",
        "    )\n",
        "\n",
        "# Constraint 4: External hours are limited by number of external hires\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            hours_external[(skillset, shift)] <= external_hires[skillset] * hours_per_shift,\n",
        "            f\"External_Hours_Limit_{skillset}_{shift}\"\n",
        "        )\n",
        "\n",
        "# Constraint 5: Total productivity must meet demand for each shift\n",
        "for shift in shifts:\n",
        "    model += (\n",
        "        pulp.lpSum(\n",
        "            (regular_hours_permanent[(skillset, shift)] + overtime_hours_permanent[(skillset, shift)]) *\n",
        "            productivity_rate[('Permanent', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) +\n",
        "        pulp.lpSum(\n",
        "            hours_external[(skillset, shift)] * productivity_rate[('External', skillset)]\n",
        "            for skillset in skillsets\n",
        "        ) >= demand[shift],\n",
        "        f\"Meet_Demand_{shift}\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alPOb0O8_nQm",
        "outputId": "ee3752f0-7b8d-441e-cbd0-7d6d48e28d75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Receiving', 'Putaway']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skillsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e01blxT95Zh"
      },
      "outputs": [],
      "source": [
        "# ====== CONSTRAINTS ======\n",
        "\n",
        "# Constraint 1: Meet minimum workload requirements\n",
        "for skillset in skillsets:\n",
        "    for shift in shifts:\n",
        "        model += (\n",
        "            regular_hours_permanent[(skillset, shift)] +\n",
        "            overtime_hours_permanent[(skillset, shift)] +\n",
        "            hours_external[(skillset, shift)] >= min_workload[(skillset, shift)],\n",
        "            f\"Min_Workload_{skillset}_{shift}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y01vpDvk-9YR"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def optimize_labour_cost(requirements, cost_per_worker):\n",
        "    prob = LpProblem(\"Minimize_Labor_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    vars = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective\n",
        "    prob += lpSum([cost_per_worker[task] * vars[task] for task in vars])\n",
        "    prob.solve()\n",
        "\n",
        "    return {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: vars[task].varValue for task in vars}\n",
        "    }\n",
        "\n",
        "@tool\n",
        "def optimize_labor(input: dict) -> dict:\n",
        "    \"\"\"Optimize labor based on task requirements and cost per task.\"\"\"\n",
        "    return optimize_labour_cost(input[\"requirements\"], input[\"costs\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVfYCKY6DExB"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEkrwtjqCTMI"
      },
      "outputs": [],
      "source": [
        "\n",
        "system_prompt = SystemMessage(\n",
        "    \"\"\"You are a Math Expert who can solve any math problem.\n",
        "    Solve the problems provided by user, by using only tools available.\n",
        "    Compute opimum value of requirement of labour for every task\"\"\"\n",
        ")\n",
        "\n",
        "tools = [optimize_labor]\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "agent_graph= create_react_agent(\n",
        "    model=model,\n",
        "    prompt=system_prompt,\n",
        "    tools=tools\n",
        "    )\n",
        "# Example 1\n",
        "input = {\"messages\":\"\"\"{\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"putaway\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"putaway\": 110}\n",
        "\"\"\"\n",
        "}\n",
        "result = agent_graph.invoke(input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODKXkDWTGOh3",
        "outputId": "54be045d-a626-4753-badc-db8f240771be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Result: The optimal number of labors for unloading, scanning, and putaway are 3, 2, and 4, respectively. The total cost is 920. \n",
            "\n",
            "Step by step execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "{\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"putaway\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"putaway\": 110}\n",
            "\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  optimize_labor (8f7e6584-5093-4ad0-8389-ddd5cac935c5)\n",
            " Call ID: 8f7e6584-5093-4ad0-8389-ddd5cac935c5\n",
            "  Args:\n",
            "    input: {\"requirements\": {\"unloading\": [3, 8],\"scanning\": [2, 6],\"putaway\": [4, 10]},\"costs\": {\"unloading\": 100,\"scanning\": 90,\"putaway\": 110}}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labor\n",
            "\n",
            "Error: 1 validation error for optimize_labor\n",
            "input\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"requirements\": {\"unloa...g\": 90,\"putaway\": 110}}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I am unable to provide a direct answer with the current tool. The tool requires a dictionary as input, but it seems I am sending a string. I will reformat the input.\n",
            "Tool Calls:\n",
            "  optimize_labor (cc8f1cb9-1c7b-4d8b-aa2c-28854dde15ab)\n",
            " Call ID: cc8f1cb9-1c7b-4d8b-aa2c-28854dde15ab\n",
            "  Args:\n",
            "    input: {'requirements': {'scanning': [2.0, 6.0], 'putaway': [4.0, 10.0], 'unloading': [3.0, 8.0]}, 'costs': {'scanning': 90.0, 'putaway': 110.0, 'unloading': 100.0}}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labor\n",
            "\n",
            "{\"status\": \"Optimal\", \"objective\": 920.0, \"assignment\": {\"scanning\": 2.0, \"putaway\": 4.0, \"unloading\": 3.0}}\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "The optimal number of labors for unloading, scanning, and putaway are 3, 2, and 4, respectively. The total cost is 920.\n"
          ]
        }
      ],
      "source": [
        "# Get the final result\n",
        "print(f\"Final Result: {result['messages'][-1].content} \\n\")\n",
        "\n",
        "print(\"Step by step execution\")\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_repr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaUI3Dic2PpJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6L0h864R2O"
      },
      "source": [
        "## Code - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecdwy1Chqo41"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def optimize_labour_cost(requirements, cost_per_worker):\n",
        "    prob = LpProblem(\"Minimize_Labor_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    vars = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective\n",
        "    prob += lpSum([cost_per_worker[task] * vars[task] for task in vars])\n",
        "    prob.solve()\n",
        "\n",
        "    return {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: vars[task].varValue for task in vars}\n",
        "    }\n",
        "\n",
        "\n",
        "@tool\n",
        "def optimize_labor(input: str) -> str:\n",
        "    \"\"\"You can parse input to structured data here (dummy example below) \"\"\"\n",
        "    requirements = {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"putaway\": (4, 10)\n",
        "    }\n",
        "    costs = {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"putaway\": 110\n",
        "    }\n",
        "\n",
        "    result = optimize_labour_cost(requirements, costs)\n",
        "    return str(result)\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n",
        "\n",
        "tools = [optimize_labor]\n",
        "agent_node = create_react_agent(model=model, tools=tools)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nu1gRKXIqo42"
      },
      "outputs": [],
      "source": [
        "# Wrap the agent_node with a callable\n",
        "agent_graph = RunnableLambda(lambda state: {\n",
        "    \"requirements\": state[\"requirements\"],\n",
        "    \"costs\" :state[\"cost\"],\n",
        "    \"output\": agent_node.invoke(state[\"prompt\"]).content\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7OItd8f4U30"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "     requirements: dict\n",
        "     costs: dict\n",
        "     output: str\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"optimize\", agent_graph)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "emTWxAOe-3_P",
        "outputId": "d9f230dd-7893-434b-c80b-794063ef7659"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'cost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-3843899204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m   4771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4772\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4773\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4774\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-16-2020979278.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      2\u001b[0m agent_graph = RunnableLambda(lambda state: {\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"requirements\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requirements\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"costs\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0magent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m })\n",
            "\u001b[0;31mKeyError\u001b[0m: 'cost'"
          ]
        }
      ],
      "source": [
        "initial_state = {\"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"putaway\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"putaway\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ8gcYuVrmCB"
      },
      "outputs": [],
      "source": [
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeU85hWhY4o2"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Agent state: the warehouse parameters\n",
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"putaway\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"putaway\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "# LangGraph node\n",
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "\n",
        "# Create LangGraph\n",
        "graph = StateGraph()\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLlUmnVzYcVh"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0, api_key=\"AIzaSyD0Rn7Qcoys2kqKQNZ4Bo9eTqYZBzddobU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA9mKy3jY7QQ"
      },
      "outputs": [],
      "source": [
        "tools = [optimize_labour_cost]\n",
        "\n",
        "# System Prompt\n",
        "system_prompt = SystemMessage(\n",
        "    \"\"\"You are a Math Expert who can solve any math problem.\n",
        "    Solve the problems provided by user, by using only tools available.\n",
        "    Do not solve the problem yourself\"\"\"\n",
        ")\n",
        "\n",
        "# Create the agent\n",
        "agent_node= create_react_agent(\n",
        "    model=model,\n",
        "    prompt=system_prompt,\n",
        "    tools=tools\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hna32arHZT-a",
        "outputId": "43efeb1e-d76d-4799-92a8-b1379d8f056a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Result: I apologize, but it seems I am encountering an error with the tool and am unable to provide a solution at this time. \n",
            "\n",
            "Step by step execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (3f5f33c8-37f6-4c70-b397-d2c990427153)\n",
            " Call ID: 3f5f33c8-37f6-4c70-b397-d2c990427153\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize for the error. It seems I made a mistake in the way I formatted the input. I should have provided a dictionary as a string.\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (2f1440c4-4e88-42bc-bea1-58e5f0bc44f9)\n",
            " Call ID: 2f1440c4-4e88-42bc-bea1-58e5f0bc44f9\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize for the repeated errors. It seems I am having trouble formatting the input correctly. I will try again, ensuring the input is a valid dictionary format.\n",
            "Tool Calls:\n",
            "  optimize_labour_cost (caeac750-0730-4411-a8c4-1c40a2337308)\n",
            " Call ID: caeac750-0730-4411-a8c4-1c40a2337308\n",
            "  Args:\n",
            "    requirements: {\"Unloading\": [3, 5], \"Scanning\": [2, 4], \"Putaway\": [4, 6]}\n",
            "    costs: {\"Unloading\": 100, \"Scanning\": 90, \"Putaway\": 110}\n",
            "================================= Tool Message =================================\n",
            "Name: optimize_labour_cost\n",
            "\n",
            "Error: 2 validation errors for optimize_labour_cost\n",
            "requirements\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": [3, 5], \"S... 4], \"Putaway\": [4, 6]}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            "costs\n",
            "  Input should be a valid dictionary [type=dict_type, input_value='{\"Unloading\": 100, \"Scan...g\": 90, \"Putaway\": 110}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/dict_type\n",
            " Please fix your mistakes.\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I apologize, but it seems I am encountering an error with the tool and am unable to provide a solution at this time.\n"
          ]
        }
      ],
      "source": [
        "# Example 1\n",
        "input = {\"messages\":[(\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\")]}\n",
        "result = agent_node.invoke(input)\n",
        "\n",
        "# Get the final result\n",
        "print(f\"Final Result: {result['messages'][-1].content} \\n\")\n",
        "\n",
        "print(\"Step by step execution\")\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_repr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVEERwig1hYd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KXo6a1U1sor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuRg43rJY8mu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjUypbXqYz_d"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2K2pbGhUJik"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_gv-_8wTjNh"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_experimental\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcygQMhSHO7M"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU \"langchain[anthropic]\" to call the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_EPvo3wj86P",
        "outputId": "a5916592-7889-4671-a2a0-393dd2107b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<AgentType.ZERO_SHOT_REACT_DESCRIPTION: 'zero-shot-react-description'>, <AgentType.REACT_DOCSTORE: 'react-docstore'>, <AgentType.SELF_ASK_WITH_SEARCH: 'self-ask-with-search'>, <AgentType.CONVERSATIONAL_REACT_DESCRIPTION: 'conversational-react-description'>, <AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'chat-zero-shot-react-description'>, <AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION: 'chat-conversational-react-description'>, <AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'structured-chat-zero-shot-react-description'>, <AgentType.OPENAI_FUNCTIONS: 'openai-functions'>, <AgentType.OPENAI_MULTI_FUNCTIONS: 'openai-multi-functions'>]\n"
          ]
        }
      ],
      "source": [
        "print(list(AgentType))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPlTzG4qtbD6"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    prompt: str\n",
        "    output: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wy7X7g_rwVD"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "jaGW6ZBsESaO",
        "outputId": "1ac8b100-a4f6-409f-b1c4-ae14f2f898d9"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Expected a callable type for `func`.Instead got an unsupported type: <class 'langgraph.graph.state.CompiledStateGraph'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2142784406>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"react_agent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, afunc, name)\u001b[0m\n\u001b[1;32m   4401\u001b[0m                 \u001b[0;34mf\"Instead got an unsupported type: {type(func)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4402\u001b[0m             )\n\u001b[0;32m-> 4403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4405\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected a callable type for `func`.Instead got an unsupported type: <class 'langgraph.graph.state.CompiledStateGraph'>"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# def agent_node(state):\n",
        "#     prompt = state[\"prompt\"]\n",
        "#     response = agent.run(prompt)\n",
        "#     return {\"output\": response}\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"react_agent\", RunnableLambda(agent_node))\n",
        "graph.set_entry_point(\"react_agent\")\n",
        "graph.add_edge(\"react_agent\", END)\n",
        "\n",
        "app = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "4sg_ZTMvFD22",
        "outputId": "f6d5e710-c3a5-49e8-c4af-ede56729475f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'CompiledStateGraph' object has no attribute 'run'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-567025205>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = app.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\"prompt\":\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\"\n\u001b[1;32m      3\u001b[0m })\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2720\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2437\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m   4771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4772\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4773\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4774\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-2649617900>\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0magent_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CompiledStateGraph' object has no attribute 'run'"
          ]
        }
      ],
      "source": [
        "response = app.invoke(\n",
        "    {\"prompt\":\"Minimize the labor cost. Unloading requires 3 to 5 workers at $100 each. Scanning needs 2 to 4 at $90. Putaway needs 4 to 6 at $110.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuTGcjT7tY6A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "iw-gpBKbFJum",
        "outputId": "cf470ccc-cab3-4669-d853-09169872ddb1"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-155192096>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#reduce inference cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mabot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-1091725969>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tools, system)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"llm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1091725969>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"llm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
        "abot = Agent(llm, [tool], system=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TVlEZQKkbCw"
      },
      "outputs": [],
      "source": [
        "from pulp import LpProblem, LpVariable, LpInteger, LpMinimize, lpSum, LpStatus, value\n",
        "\n",
        "def optimize_labour_cost(daily_requirements, cost_per_worker):\n",
        "    \"\"\"\n",
        "    daily_requirements: dict of {task: (min_workers, max_workers)}\n",
        "    cost_per_worker: dict of {task: cost_per_worker}\n",
        "    \"\"\"\n",
        "    prob = LpProblem(\"Minimize_Labour_Cost\", LpMinimize)\n",
        "\n",
        "    # Decision variables: workers assigned per task\n",
        "    workers = {\n",
        "        task: LpVariable(f\"workers_{task}\", lowBound=low, upBound=high, cat=LpInteger)\n",
        "        for task, (low, high) in daily_requirements.items()\n",
        "    }\n",
        "\n",
        "    # Objective function: minimize total cost\n",
        "    prob += lpSum([cost_per_worker[task] * workers[task] for task in workers])\n",
        "\n",
        "    # Solve\n",
        "    prob.solve()\n",
        "\n",
        "    # Result\n",
        "    result = {\n",
        "        \"status\": LpStatus[prob.status],\n",
        "        \"objective\": value(prob.objective),\n",
        "        \"assignment\": {task: workers[task].varValue for task in workers}\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "wDXTZ2Xzp1rn",
        "outputId": "8414671c-9aa8-4741-be53-9cc0c6d8f440"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Must provide state_schema or input and output",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3814180203>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create LangGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_schema, config_schema, input, output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide state_schema or input and output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mstate_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValueError\u001b[0m: Must provide state_schema or input and output"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Agent state: the warehouse parameters\n",
        "initial_state = {\n",
        "    \"requirements\": {\n",
        "        \"unloading\": (3, 8),\n",
        "        \"scanning\": (2, 6),\n",
        "        \"putaway\": (4, 10)\n",
        "    },\n",
        "    \"costs\": {\n",
        "        \"unloading\": 100,\n",
        "        \"scanning\": 90,\n",
        "        \"putaway\": 110\n",
        "    }\n",
        "}\n",
        "\n",
        "# LangGraph node\n",
        "def optimization_node(state):\n",
        "    result = optimize_labour_cost(state[\"requirements\"], state[\"costs\"])\n",
        "    return {\"result\": result}\n",
        "\n",
        "# Wrap node\n",
        "opt_node = RunnableLambda(optimization_node)\n",
        "\n",
        "# Create LangGraph\n",
        "graph = StateGraph()\n",
        "graph.add_node(\"optimize\", opt_node)\n",
        "graph.set_entry_point(\"optimize\")\n",
        "graph.add_edge(\"optimize\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run\n",
        "output = app.invoke(initial_state)\n",
        "print(output[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IC2NUh3prpAk"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
